{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaseEnsemble,\n",
    "    RandomForestRegressor,\n",
    "    RandomTreesEmbedding,\n",
    "    ExtraTreesClassifier,\n",
    "    ExtraTreesRegressor,\n",
    "    BaggingClassifier,\n",
    "    BaggingRegressor,\n",
    "    IsolationForest,\n",
    "    GradientBoostingRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    VotingClassifier,\n",
    "    VotingRegressor,\n",
    "    StackingClassifier,\n",
    "    StackingRegressor,\n",
    "    HistGradientBoostingClassifier,\n",
    "    HistGradientBoostingRegressor\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1)\n",
    "\n",
    "#the time period constant used to calculate the EMA\n",
    "DAYS_FOR_EMA = 21\n",
    "#the time period constant used to calculate the RSI\n",
    "DAYS_FOR_RSI = 14\n",
    "\n",
    "#constant used to determine the length of each period to get the average of close price\n",
    "CLOSE_PRICE_MEAN_DAYS = 7\n",
    "\n",
    "#period length used fo MA volume calculation\n",
    "MA_VOLUME_DAYS = 14\n",
    "\n",
    "RANDOM_STATE = 45\n",
    "\n",
    "TEST_SIZE = 0.1251353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaseEnsemble,\n",
    "    RandomForestRegressor,\n",
    "    RandomTreesEmbedding,\n",
    "    ExtraTreesClassifier,\n",
    "    ExtraTreesRegressor,\n",
    "    BaggingClassifier,\n",
    "    BaggingRegressor,\n",
    "    IsolationForest,\n",
    "    GradientBoostingRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    VotingClassifier,\n",
    "    VotingRegressor,\n",
    "    StackingClassifier,\n",
    "    StackingRegressor,\n",
    "    HistGradientBoostingClassifier,\n",
    "    HistGradientBoostingRegressor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    " https://www.kaggle.com/datasets/kannan1314/amazon-stock-price-all-time\n",
    " Basic CSV file with open, high, low, close, adjusted close price and volume of Amazon stock for each day.\n",
    "\n",
    " https://www.kaggle.com/datasets/henryshan/amazon-com-inc-amzn\n",
    " The dataset includes the daily Amazon.com, Inc. stock price. (BU KULLANILMAYABİLİR)\n",
    "\n",
    "\n",
    " https://www.kaggle.com/datasets/varpit94/amazon-stock-data\n",
    " Amazon (AMZN) historic prices (USD), daily data.\n",
    "\n",
    "https://www.kaggle.com/datasets/beeru999/amazon-stock-prices1997-2021\n",
    "This CSV file contains historical stock price data for Amazon (AMZN) from May 15, 1997, to April 5, 2023. The dataset includes the following columns:\n",
    "\n",
    "Date: The date of the trading day.\n",
    "Open: The opening price of the stock on that day.\n",
    "High: The highest price the stock reached during the trading day.\n",
    "Low: The lowest price the stock reached during the trading day.\n",
    "Close: The closing price of the stock on that day.\n",
    "Adj Close: The adjusted closing price, which accounts for dividends, stock splits, and other adjustments.\n",
    "Volume: The number of shares traded during the day.\n",
    "'''\n",
    "#df1 = pd.read_csv('data/Amazon.csv')\n",
    "#df2 = pd.read_csv('data/AMZN.csv')\n",
    "#df3 = pd.read_csv('data/AMZN (1).csv')\n",
    "#TODO şimdilik tek dataset, datalar farklı kafa karışmasın\n",
    "df4 = pd.read_csv('data/AMZN (2).csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display(df1.iloc[-1:])\n",
    "#display(df2.iloc[-1:])\n",
    "#display(df3.iloc[-1:])\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DATALARDA HER GÜN BULUNMUYOR\n",
    "\n",
    "RSI EMA falan hesaplarken timedelta değil index bakalım (ya da uygunsuz mu olur)\n",
    "'''\n",
    "\n",
    "#TODO MACD sonra bak, hesaplayabilmek için 12 günlük ve 26 günlük EMA da gerekiyor\n",
    "#TODO volatility kısmı bak (yapılmalı mı?)\n",
    "#TODO günden güne volume kısmında yüzdelik kısmına bak (pzts salı %40'tan %60'a çıkmış vs.) (buna bakılabilir mi?)\n",
    "\n",
    "#TODO önceki günleri de hesaba kat\n",
    "#TODO direk close tahmin etmek yerine, yukarı mı gidecek aşağı mı gidecek onlara bak\n",
    "#TODO close, volume veya diğer fiyatla ilgilli özelliklere log transofrmation yap varience stabilizasyonu için\n",
    "#TODO scaling yap\n",
    "\n",
    "#TODO train test bölerken son günler test olsun\n",
    "\n",
    "\n",
    "def is_month_start(row: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given date is the start of the month.\n",
    "\n",
    "    Args:\n",
    "    row (dict): A dictionary containing a 'Date' key with the date string.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the date is the end of the month, False otherwise.\n",
    "    \"\"\"\n",
    "    return row['Date'].split('-')[2] == '01'\n",
    "\n",
    "def is_month_end(row: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given date is the end of the month.\n",
    "\n",
    "    Args:\n",
    "    row (dict): A dictionary containing a 'Date' key with the date string.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the date is the end of the month, False otherwise.\n",
    "    \"\"\"\n",
    "    #diğeri gibi yapmadık, 28-29 Şubat'ı da dahil edebilmek için\n",
    "    date_str = row['Date']\n",
    "    date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    last_day = calendar.monthrange(date.year, date.month)[1]\n",
    "    return date.day == last_day\n",
    "\n",
    "df4[\"month_start\"]=df4.apply(is_month_start, axis=1, inplace=True)\n",
    "df4[\"month_end\"]=df4.apply(is_month_end, axis=1, inplace=True)\n",
    "\n",
    "df4[\"high_low_diff\"] = df4[\"High\"] - df4[\"Low\"]\n",
    "\n",
    "df4[\"open_close_diff\"] = df4[\"Open\"] - df4[\"Close\"]\n",
    "\n",
    "df4[\"volume*Close\"] = df4[\"Volume\"] * df4[\"Close\"]\n",
    "\n",
    "'''DATA HER BİR GÜNÜ İÇERMİYOR, 7 GÜNLÜK ORTALAMA VS. MANTIKLI MI?'''\n",
    "\n",
    "#14 gün de olabilir\n",
    "def get_close_avg(row: Dict, days: int, df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Get the average of the closing prices of the previous 7 days.\n",
    "\n",
    "    Args:\n",
    "    row (dict): A dictionary containing a 'Date' key with the date string.\n",
    "\n",
    "    Returns:\n",
    "    float: The average of the closing prices of the previous 7 days.\n",
    "    \"\"\"\n",
    "    #get the previous 7 days\n",
    "    if row.name < 7:\n",
    "        return 0\n",
    "    else:\n",
    "        index = row.name\n",
    "        close_avg = df.loc[index-days:index][\"Close\"].mean()\n",
    "        return close_avg\n",
    "\n",
    "df4[f\"close_price_mean_{CLOSE_PRICE_MEAN_DAYS}_days\"] = df4.apply(lambda row: get_close_avg(row, CLOSE_PRICE_MEAN_DAYS, df4), axis=1, inplace=True)\n",
    "\n",
    "def calculate_ema(row: Dict, ema_period: int, df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Exponential Moving Average (EMA) for a given row.\n",
    "\n",
    "    Args:\n",
    "    row (dict): A dictionary containing the row data.\n",
    "    ema_period (int): The number of periods to consider for calculating EMA.\n",
    "\n",
    "    Returns:\n",
    "    float: The EMA value for the given row.\n",
    "    \"\"\"\n",
    "    #for initial prices, return the average of close prices over n number of periods (a simple moving average)\n",
    "    if row.name < ema_period:\n",
    "        return df4.loc[:row.name, 'Close'].mean()\n",
    "    #for others, calculate the EMA normally\n",
    "    else:\n",
    "        previous_ema = df4.loc[row.name - 1, f'ema_{ema_period}']\n",
    "        close_price = row['Close']\n",
    "        smoothing_constant = 2 / (ema_period + 1)\n",
    "        ema = (close_price - previous_ema) * smoothing_constant + previous_ema\n",
    "        return ema\n",
    "\n",
    "df4[f'ema_{DAYS_FOR_EMA}'] = df4.apply(lambda row: calculate_ema(row, DAYS_FOR_EMA, df4), axis=1)\n",
    "\n",
    "#RSI için ilk 21 gün olmuyor, ilk 21 günü atla\n",
    "def calculate_RSI(df: pd.DataFrame, row: Dict, rsi_period: int) -> float:\n",
    "\n",
    "    '''Calculates the RSI for given row and returns it\n",
    "    Args:\n",
    "    df: dataframe used (added as parameter, global variables can be buggy thats why)\n",
    "    row (dict): A dictionary containing the row data.\n",
    "    rsi_period (int): The number of periods to consider for calculating RSI.\n",
    "\n",
    "    Returns:\n",
    "    float: The RSI value for the given row. \n",
    "    '''\n",
    "    #get the index of row (we dont have each day thats why we dont use timedelta)\n",
    "    index = row.name\n",
    "    \n",
    "    #close prices of previous 21 days\n",
    "    prev_close = df.iloc[index-rsi_period:index]\n",
    "\n",
    "    def calculate_difference(row: Dict, df: pd.DataFrame) -> float:\n",
    "        '''Calculates the difference between close prices.\n",
    "        Returns zero for the first day\n",
    "        Args:\n",
    "        row (dict): a row in dataframe\n",
    "        df (DataFrame): dataframe\n",
    "\n",
    "        Returns:\n",
    "            diff (float): the difference between two rows close prices. Zero if first day\n",
    "        '''\n",
    "        #first day\n",
    "        if row.name == 0:\n",
    "            return 0\n",
    "        #-1 to get the previous day\n",
    "        index = row.name - 1\n",
    "        diff = row[\"Close\"] - df.loc[index][\"Close\"]\n",
    "\n",
    "        return diff\n",
    "\n",
    "    #don't include the first day for RSI (cant calculate the difference for first day)\n",
    "    prev_close[\"diff\"] = prev_close.apply(calculate_difference, axis=1)\n",
    "    \n",
    "    #TODO check this calculation\n",
    "    avg_gains = prev_close[prev_close[\"diff\"] > 0][\"diff\"].mean()\n",
    "    avg_losses = prev_close[prev_close[\"diff\"] < 0][\"diff\"].mean()\n",
    "    \n",
    "    #calculate and return\n",
    "    rsi = avg_gains / avg_losses\n",
    "    return rsi\n",
    "\n",
    "df4[f\"RSI_{DAYS_FOR_RSI}_days\"] = df4.apply(lambda row: calculate_RSI(df4, row, DAYS_FOR_RSI), axis=1)\n",
    "\n",
    "def calculate_liquidity(row: Dict) -> float:\n",
    "    '''Calculates the liquidity for the given row\n",
    "    volume / close\n",
    "    Args:\n",
    "    row (dict): a row of the dataframe\n",
    "\n",
    "    Returns:\n",
    "        the liquidity of the row\n",
    "    '''\n",
    "    return row[\"Volume\"] / row[\"Close\"]\n",
    "\n",
    "df4[\"liquidity\"] = df4.apply(calculate_liquidity, axis=1)\n",
    "\n",
    "def calculate_MA_volume(row: Dict, days: int, df: pd.DataFrame) -> float:\n",
    "    '''Calculates the volume moving average over a given period of time\n",
    "    Args:\n",
    "    row (dict): a row of dataframe\n",
    "    days (int): the length of a period\n",
    "    df (Dataframe): dataframe to operate on\n",
    "    '''\n",
    "\n",
    "    if row.name < days:\n",
    "        return 0\n",
    "    else:\n",
    "        index = row.name\n",
    "        avg = df.loc[index-days: index][\"Volume\"].mean()\n",
    "        return avg\n",
    "    \n",
    "df4[f\"volume_MA_{MA_VOLUME_DAYS}_days\"] = df4.apply(calculate_MA_volume, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model choose and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "scheduler kullan\n",
    "\n",
    "linear regression\n",
    "\n",
    "from r_model import Ridge\n",
    "\n",
    "CNN\n",
    "\n",
    "dropout\n",
    "\n",
    "dense\n",
    "\n",
    "mse kullanıldı genelde\n",
    "\n",
    "birden fazla model\n",
    "\n",
    "TRACK transformer model\n",
    "\n",
    "loss plateau\n",
    "\n",
    "her okuduğunda datada perturbation yap\n",
    "\n",
    "pytoerch yoerine tensorflow kullanmak daha etkili olabilir\n",
    "\n",
    "hipotez testi\n",
    "\n",
    "Man-Whittney U test\n",
    "\n",
    "VBO\n",
    "\n",
    "greed search\n",
    "\n",
    "gridf\n",
    "\n",
    "randomizedCV search\n",
    "\n",
    "torch.inference_mode\n",
    "\n",
    "LSTM modülü\n",
    "\n",
    "GRU modülü\n",
    "\n",
    "tensor çevir\n",
    "\n",
    "denormalize data\n",
    "\n",
    "fakrlı grafikler çizdir\n",
    "\n",
    "seed model\n",
    "'''\n",
    "\n",
    "X = df4.columns.tolist()\n",
    "y = np.stack(df4[\"Close\"])\n",
    "\n",
    "x_train, y_train, x_test, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "# Creating models for each classifier\n",
    "\n",
    "def define_models() -> List[Any]:\n",
    "    '''Defines the classifier models and returns them in a list\n",
    "    Args:\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    models (list): a list of models\n",
    "    '''\n",
    "    # RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier()\n",
    "\n",
    "    # GradientBoostingClassifier\n",
    "    gb_model = GradientBoostingClassifier()\n",
    "\n",
    "    # AdaBoostClassifier\n",
    "    ab_model = AdaBoostClassifier()\n",
    "\n",
    "    # ExtraTreesClassifier\n",
    "    et_model = ExtraTreesClassifier()\n",
    "\n",
    "    # BaggingClassifier\n",
    "    bagging_model = BaggingClassifier()\n",
    "\n",
    "    # IsolationForest\n",
    "    if_model = IsolationForest()\n",
    "\n",
    "    # VotingClassifier\n",
    "    voting_model = VotingClassifier(estimators=[])\n",
    "\n",
    "    # StackingClassifier\n",
    "    stacking_model = StackingClassifier(estimators=[])\n",
    "\n",
    "    # HistGradientBoostingClassifier\n",
    "    hist_gb_model = HistGradientBoostingClassifier()\n",
    "\n",
    "    models = [\n",
    "        rf_model,\n",
    "        gb_model,\n",
    "        ab_model,\n",
    "        et_model,\n",
    "        bagging_model,\n",
    "        if_model,\n",
    "        voting_model,\n",
    "        stacking_model,\n",
    "        hist_gb_model\n",
    "    ]\n",
    "\n",
    "    return models\n",
    "\n",
    "models: list = define_models()\n",
    "\n",
    "#TODO ilk etapta k-cross validation yapmayacağız, sonra eklenecek\n",
    "\n",
    "#dictionary seçtik histogram plot yaparken kolaylık olsun diye\n",
    "histogram_data: Dict = {}\n",
    "for m in models:\n",
    "    m.fit(x_train, y_train)\n",
    "    y_pred = m.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    model_name = m.__class__.__name__\n",
    "    histogram_data[model_name] = score\n",
    "\n",
    "\n",
    "# Extracting model names and accuracy scores\n",
    "model_names = list(histogram_data.keys())\n",
    "accuracy_scores = list(histogram_data.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model_names, scores):\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(model_names, accuracy_scores, color='skyblue')\n",
    "    plt.xlabel('Model Names')\n",
    "    plt.ylabel('Accuracy Scores')\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.title('Model Accuracy Scores')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print_results(model_names, accuracy_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsoft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
